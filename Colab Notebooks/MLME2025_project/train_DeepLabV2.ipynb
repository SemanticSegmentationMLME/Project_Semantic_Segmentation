{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JXg1dlQzbB7","executionInfo":{"status":"ok","timestamp":1750607932880,"user_tz":-120,"elapsed":8933,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"}},"outputId":"2f0976a7-a080-43e8-b8f5-0bac4103afcf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n","Collecting yacs>=0.1.6 (from fvcore)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore)\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.14.0)\n","Collecting portalocker (from iopath>=0.1.7->fvcore)\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=4b75584251e710d1d0f71c2a14b6c5a5ffed707bef25fc67d50b591138e3190c\n","  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=2a8964e2f97a95fc44e124e900325dc4741971a3b3fbeeba6d91258590bed6f8\n","  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n","Successfully built fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, fvcore\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\n"]}],"source":["!pip install fvcore"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24036,"status":"ok","timestamp":1750636585597,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"},"user_tz":-120},"id":"lfWH4vmfqbSE","outputId":"4a7fc0d2-12ef-4ae3-fe00-97b6982fa540"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1RYSbBavzuDv"},"outputs":[],"source":["# import modules\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import torch\n","import torch.nn as nn\n","import time\n","import torch.optim as optim\n","import os\n","import sys\n","\n","from torchvision import transforms\n","from torchvision.transforms import InterpolationMode\n","from fvcore.nn import FlopCountAnalysis, flop_count_table\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjG87TqmoVov"},"outputs":[],"source":["PROJECT_PATH = '/content/drive/MyDrive/Colab Notebooks/MLME2025_project'\n","CITYSCAPES_DIR = '/content/drive/MyDrive/Cityspaces/'\n","PRETRAIN_MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/MLME2025_project/models/DeepLabV2/deeplab_resnet_pretrained_imagenet.pth'\n","BEST_MODEL_SAVE_PATH = '/content/drive/MyDrive/Colab Notebooks/MLME2025_project/models/DeepLabV2/checkpoints_training/best_model_DeepLab.pth'\n","LAST_EPOCH_SAVE_PATH = '/content/drive/MyDrive/Colab Notebooks/MLME2025_project/models/DeepLabV2/checkpoints_training/last_epoch_DeepLab.pth'\n","\n","NUM_CLASSES = 19\n","H = 512\n","W = 1024\n","BATCH_SIZE = 4\n","NUM_WORKERS = 4\n","LEARNING_RATE = 0.001\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 0.0005"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AOyoQ_aqzxRk"},"outputs":[],"source":["os.chdir(PROJECT_PATH)\n","sys.path.append(os.getcwd())\n","\n","from datasets.cityscapes import CityScapes\n","from utils.utils import poly_lr_scheduler_with_backbone, fast_hist, per_class_iou, mean_iou\n","import models.DeepLabV2.deeplabv2 as deeplab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHDDxkDpz197"},"outputs":[],"source":["torch.manual_seed(42)\n","np.random.seed(42)\n","random.seed(0)\n","torch.cuda.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tFDGVBjz_8e"},"outputs":[],"source":["# transformers data\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        # resize as asked in the project + interpolation\n","        transforms.Resize((H, W), interpolation=InterpolationMode.BILINEAR),\n","        # transform to tensor + normalize\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize((H, W), interpolation=InterpolationMode.BILINEAR),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","}\n","\n","# transformers label\n","\n","label_transform = transforms.Compose([\n","    # resize as asked in the project + nearest\n","    transforms.Resize((H, W), interpolation=InterpolationMode.NEAREST),\n","    # transform to tensor without normalization\n","    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n","])\n","\n","# create cityscapes datasets\n","\n","cityscapes_datasets = {\n","    x:  CityScapes(\n","        data_path=CITYSCAPES_DIR,\n","        split=x,\n","        transform=data_transforms[x],\n","        label_transform=label_transform\n","      )\n","\n","    for x in ['train', 'val']\n","}\n","\n","# create cityscapes dataloader\n","\n","cityscapes_dataloaders = {\n","    x: torch.utils.data.DataLoader(\n","        cityscapes_datasets[x],\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        shuffle=True,\n","        pin_memory=True\n","      )\n","    for x in ['train', 'val']\n","}\n","\n","# save datasets size\n","\n","dataset_sizes = {x: len(cityscapes_datasets[x]) for x in ['train', 'val']}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2229,"status":"ok","timestamp":1749955493833,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"},"user_tz":-120},"id":"Bkp79sSV0UDX","outputId":"a0dda14f-4670-4d45-ffd5-e8d86557e0c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["CITYSCAPES DATASETS: type=<class 'dict'>, keys=dict_keys(['train', 'val']) \n","\n","TRAIN DATASETS: type=<class 'datasets.cityscapes.CityScapes'>, len=1572 \n","\n","VAL DATASETS: type=<class 'datasets.cityscapes.CityScapes'>, len=500 \n","\n","SINGLE IMAGE: type=<class 'dict'>, keys=dict_keys(['x', 'y']) \n","\n","'x': type=<class 'torch.Tensor'>, shape=torch.Size([3, 512, 1024]) \n","\n","'y': type=<class 'torch.Tensor'>, shape=torch.Size([512, 1024]) \n","\n"]}],"source":["# print data type and sizes of dataset\n","print(f\"CITYSCAPES DATASETS: type={type(cityscapes_datasets)}, keys={cityscapes_datasets.keys()} \\n\")\n","print(f\"TRAIN DATASETS: type={type(cityscapes_datasets['train'])}, len={len(cityscapes_datasets['train'])} \\n\")\n","print(f\"VAL DATASETS: type={type(cityscapes_datasets['val'])}, len={len(cityscapes_datasets['val'])} \\n\")\n","print(f\"SINGLE IMAGE: type={type(cityscapes_datasets['train'][0])}, keys={cityscapes_datasets['train'][0].keys()} \\n\")\n","\n","image, label = cityscapes_datasets['train'][0].values()\n","print(f\"'x': type={type(image)}, shape={image.shape} \\n\")\n","print(f\"'y': type={type(label)}, shape={label.shape} \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12384,"status":"ok","timestamp":1749955506220,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"},"user_tz":-120},"id":"4Tv-SohH1ibV","outputId":"23ced966-5afc-4ceb-dba0-21c3701bab70"},"outputs":[{"output_type":"stream","name":"stdout","text":["CITYSCAPES DATALOADER: type=<class 'dict'>, keys=dict_keys(['train', 'val']) \n","\n","TRAIN DATALOADER: type=<class 'torch.utils.data.dataloader.DataLoader'>, len=393 \n","\n","VAL DATALOADER: type=<class 'torch.utils.data.dataloader.DataLoader'>, len=125 \n","\n","BATCH INPUTS: type=<class 'torch.Tensor'>, shape=torch.Size([4, 3, 512, 1024]) \n","\n","BATCH LABELS: type=<class 'torch.Tensor'>, shape=torch.Size([4, 512, 1024]) \n","\n"]}],"source":["# print data type and sizes of dataloader\n","print(f\"CITYSCAPES DATALOADER: type={type(cityscapes_dataloaders)}, keys={cityscapes_dataloaders.keys()} \\n\")\n","print(f\"TRAIN DATALOADER: type={type(cityscapes_dataloaders['train'])}, len={len(cityscapes_dataloaders['train'])} \\n\")\n","print(f\"VAL DATALOADER: type={type(cityscapes_dataloaders['val'])}, len={len(cityscapes_dataloaders['val'])} \\n\")\n","\n","for batch in cityscapes_dataloaders['train']:\n","  inputs = batch['x']\n","  labels = batch['y']\n","  break\n","\n","print(f\"BATCH INPUTS: type={type(inputs)}, shape={inputs.shape} \\n\")\n","print(f\"BATCH LABELS: type={type(labels)}, shape={labels.shape} \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EznbXYGM0vaH"},"outputs":[],"source":["def train_model(model, data_loader, dataset_sizes, criterion, optimizer,\n","                last_epoch_save_path, best_model_save_path, num_epochs=1,\n","                init_lr=0.01, prev_num_epoch=0, prev_best_miou=0,\n","                total_number_epochs=50):\n","\n","    since = time.time()\n","\n","    best_miou = prev_best_miou\n","    best_per_class_iou = None\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        since_epoch = time.time()\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # training mode\n","            else:\n","                model.eval()   # evaluate mode\n","\n","            running_loss = 0.0\n","\n","            hist = np.zeros((NUM_CLASSES, NUM_CLASSES))\n","            miou = 0\n","\n","            # Iterate over data\n","            for batch in data_loader[phase]:\n","                inputs = batch['x']\n","                labels = batch['y']\n","\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","\n","                    if phase == 'train':\n","                        loss = criterion(outputs[0], labels) # requires output as [B, C, H, W] and label as [B, H, W]\n","                        running_loss += loss.item()\n","                        loss.backward()\n","\n","                        optimizer.step()\n","\n","                        preds = torch.argmax(outputs[0], dim=1) # from [B, C, H, W] to [B, H, W]\n","                        hist += fast_hist(\n","                                 preds.cpu().data.numpy().flatten(),\n","                                 labels.cpu().data.numpy().flatten(),\n","                                 NUM_CLASSES\n","                                )\n","\n","                    else:\n","                        loss = criterion(outputs, labels)\n","                        running_loss += loss.item()\n","\n","                        preds = torch.argmax(outputs, dim=1)\n","                        hist += fast_hist(\n","                                 preds.cpu().data.numpy().flatten(),\n","                                 labels.cpu().data.numpy().flatten(),\n","                                 NUM_CLASSES\n","                                )\n","\n","            ious = per_class_iou(hist) * 100\n","            miou = mean_iou(ious)\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {miou:.4f}')\n","\n","        # Update learning rate with poly_lr_scheduler\n","        next_lr = poly_lr_scheduler_with_backbone(optimizer, init_lr, prev_num_epoch, total_number_epochs)\n","        prev_num_epoch += 1\n","\n","        # save the best model\n","        if miou > best_miou:\n","            best_miou = miou\n","            best_per_class_iou = ious\n","            torch.save({\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","            }, best_model_save_path)\n","\n","        # save the last model\n","        torch.save({\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","        }, last_epoch_save_path)\n","\n","        time_epoch = time.time() - since_epoch\n","        print(f'Epoch complete in {time_epoch // 60:.0f}m {time_epoch % 60:.0f}s')\n","        print(f'Next Learning Rate: {next_lr}')\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('-' * 20)\n","    print()\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val MIOU: {best_miou:4f}')\n","    print(f'Best val per class IOU: {best_per_class_iou}')\n","    print()\n","    print(f'Total Epochs completed: {prev_num_epoch}')\n","\n","    return model, time_elapsed, best_miou, best_per_class_iou"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1749955506295,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"},"user_tz":-120},"id":"_B12Mw3tW0Ax","outputId":"4e745d57-131f-4f33-a6bf-19cbaf8f2478"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27662,"status":"ok","timestamp":1749955533968,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"},"user_tz":-120},"id":"nmHUPGDu01J4","outputId":"314c7282-0e1a-4807-c3bd-8823da177316"},"outputs":[{"output_type":"stream","name":"stdout","text":["Deeplab pretraining loading...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/_compile.py:32: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n","  return disable_fn(*args, **kwargs)\n"]}],"source":["model = deeplab.get_deeplab_v2(\n","    num_classes=NUM_CLASSES,\n","    pretrain=True,\n","    pretrain_model_path=PRETRAIN_MODEL_PATH\n",")\n","model = model.to(device)\n","\n","optimizer = optim.SGD(\n","    params=[\n","    {'params': model.get_1x_lr_params_no_scale(), 'lr': LEARNING_RATE, 'initial_lr': LEARNING_RATE},\n","    {'params': model.get_10x_lr_params(), 'lr': LEARNING_RATE * 10, 'initial_lr': LEARNING_RATE * 10}\n","    ],\n","    momentum=MOMENTUM,\n","    weight_decay=WEIGHT_DECAY\n",")\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=255)\n","\n","\n","# load checkpoint previous epochs\n","checkpoint = torch.load(LAST_EPOCH_SAVE_PATH)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZV8d9Yl6Xu15","outputId":"f006ef5f-e857-46ea-d320-2014f2c405d3","executionInfo":{"status":"ok","timestamp":1749960485306,"user_tz":-120,"elapsed":4951336,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","----------\n","train Loss: 0.0164 Acc: 86.1205\n","val Loss: 0.0641 Acc: 61.2583\n","Epoch complete in 18m 41s\n","Next Learning Rate: [0.00012589254117941672, 0.001258925411794167]\n","\n","Epoch 2/5\n","----------\n","train Loss: 0.0164 Acc: 86.0795\n","val Loss: 0.0644 Acc: 60.9707\n","Epoch complete in 15m 57s\n","Next Learning Rate: [0.00010298666348361787, 0.0010298666348361786]\n","\n","Epoch 3/5\n","----------\n","train Loss: 0.0164 Acc: 86.1116\n","val Loss: 0.0648 Acc: 60.8351\n","Epoch complete in 15m 57s\n","Next Learning Rate: [7.949432487547622e-05, 0.0007949432487547622]\n","\n","Epoch 4/5\n","----------\n","train Loss: 0.0164 Acc: 86.1507\n","val Loss: 0.0642 Acc: 61.2457\n","Epoch complete in 15m 57s\n","Next Learning Rate: [5.518918645844863e-05, 0.0005518918645844864]\n","\n","Epoch 5/5\n","----------\n","train Loss: 0.0163 Acc: 86.1526\n","val Loss: 0.0652 Acc: 60.8997\n","Epoch complete in 15m 55s\n","Next Learning Rate: [2.9575152732566297e-05, 0.000295751527325663]\n","\n","--------------------\n","\n","Training complete in 82m 31s\n","Best val MIOU: 61.378382\n","Best val per class IOU: None\n","\n","Total Epochs completed: 50\n"]}],"source":["model, time_elapsed, best_miou, best_per_class_iou = train_model(\n","    model=model,\n","    data_loader=cityscapes_dataloaders,\n","    dataset_sizes=dataset_sizes,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    last_epoch_save_path=LAST_EPOCH_SAVE_PATH,\n","    best_model_save_path=BEST_MODEL_SAVE_PATH,\n","    num_epochs=5,\n","    init_lr=LEARNING_RATE,\n","    prev_num_epoch=45,\n","    prev_best_miou=61.378382,\n","    total_number_epochs=50\n",")"]},{"cell_type":"code","source":["# FLOPS\n","\n","model = deeplab.get_deeplab_v2(\n","    num_classes=NUM_CLASSES,\n","    pretrain=True,\n","    pretrain_model_path=PRETRAIN_MODEL_PATH\n",")\n","\n","image = torch.zeros((1, 3, H, W))\n","\n","flops = FlopCountAnalysis(model, image)\n","print(flop_count_table(flops))"],"metadata":{"id":"taQoYkGf_ad5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750608244098,"user_tz":-120,"elapsed":4465,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"}},"outputId":"f87198ef-1b18-4809-a408-3ca676b09cfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Deeplab pretraining loading...\n","| module                         | #parameters or shape   | #flops     |\n","|:-------------------------------|:-----------------------|:-----------|\n","| model                          | 43.901M                | 0.376T     |\n","|  conv1                         |  9.408K                |  1.233G    |\n","|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n","|  bn1                           |  0.128K                |  41.943M   |\n","|   bn1.weight                   |   (64,)                |            |\n","|   bn1.bias                     |   (64,)                |            |\n","|  layer1                        |  0.216M                |  7.295G    |\n","|   layer1.0                     |   75.008K              |   2.55G    |\n","|    layer1.0.conv1              |    4.096K              |    0.136G  |\n","|    layer1.0.bn1                |    0.128K              |    10.609M |\n","|    layer1.0.conv2              |    36.864K             |    1.222G  |\n","|    layer1.0.bn2                |    0.128K              |    10.609M |\n","|    layer1.0.conv3              |    16.384K             |    0.543G  |\n","|    layer1.0.bn3                |    0.512K              |    42.436M |\n","|    layer1.0.downsample         |    16.896K             |    0.586G  |\n","|   layer1.1                     |   70.4K                |   2.372G   |\n","|    layer1.1.conv1              |    16.384K             |    0.543G  |\n","|    layer1.1.bn1                |    0.128K              |    10.609M |\n","|    layer1.1.conv2              |    36.864K             |    1.222G  |\n","|    layer1.1.bn2                |    0.128K              |    10.609M |\n","|    layer1.1.conv3              |    16.384K             |    0.543G  |\n","|    layer1.1.bn3                |    0.512K              |    42.436M |\n","|   layer1.2                     |   70.4K                |   2.372G   |\n","|    layer1.2.conv1              |    16.384K             |    0.543G  |\n","|    layer1.2.bn1                |    0.128K              |    10.609M |\n","|    layer1.2.conv2              |    36.864K             |    1.222G  |\n","|    layer1.2.bn2                |    0.128K              |    10.609M |\n","|    layer1.2.conv3              |    16.384K             |    0.543G  |\n","|    layer1.2.bn3                |    0.512K              |    42.436M |\n","|  layer2                        |  1.22M                 |  10.316G   |\n","|   layer2.0                     |   0.379M               |   3.213G   |\n","|    layer2.0.conv1              |    32.768K             |    0.275G  |\n","|    layer2.0.bn1                |    0.256K              |    5.366M  |\n","|    layer2.0.conv2              |    0.147M              |    1.236G  |\n","|    layer2.0.bn2                |    0.256K              |    5.366M  |\n","|    layer2.0.conv3              |    65.536K             |    0.55G   |\n","|    layer2.0.bn3                |    1.024K              |    21.466M |\n","|    layer2.0.downsample         |    0.132M              |    1.121G  |\n","|   layer2.1                     |   0.28M                |   2.368G   |\n","|    layer2.1.conv1              |    65.536K             |    0.55G   |\n","|    layer2.1.bn1                |    0.256K              |    5.366M  |\n","|    layer2.1.conv2              |    0.147M              |    1.236G  |\n","|    layer2.1.bn2                |    0.256K              |    5.366M  |\n","|    layer2.1.conv3              |    65.536K             |    0.55G   |\n","|    layer2.1.bn3                |    1.024K              |    21.466M |\n","|   layer2.2                     |   0.28M                |   2.368G   |\n","|    layer2.2.conv1              |    65.536K             |    0.55G   |\n","|    layer2.2.bn1                |    0.256K              |    5.366M  |\n","|    layer2.2.conv2              |    0.147M              |    1.236G  |\n","|    layer2.2.bn2                |    0.256K              |    5.366M  |\n","|    layer2.2.conv3              |    65.536K             |    0.55G   |\n","|    layer2.2.bn3                |    1.024K              |    21.466M |\n","|   layer2.3                     |   0.28M                |   2.368G   |\n","|    layer2.3.conv1              |    65.536K             |    0.55G   |\n","|    layer2.3.bn1                |    0.256K              |    5.366M  |\n","|    layer2.3.conv2              |    0.147M              |    1.236G  |\n","|    layer2.3.bn2                |    0.256K              |    5.366M  |\n","|    layer2.3.conv3              |    65.536K             |    0.55G   |\n","|    layer2.3.bn3                |    1.024K              |    21.466M |\n","|  layer3                        |  26.09M                |  0.22T     |\n","|   layer3.0                     |   1.512M               |   12.746G  |\n","|    layer3.0.conv1              |    0.131M              |    1.099G  |\n","|    layer3.0.bn1                |    0.512K              |    10.733M |\n","|    layer3.0.conv2              |    0.59M               |    4.946G  |\n","|    layer3.0.bn2                |    0.512K              |    10.733M |\n","|    layer3.0.conv3              |    0.262M              |    2.198G  |\n","|    layer3.0.bn3                |    2.048K              |    42.931M |\n","|    layer3.0.downsample         |    0.526M              |    4.439G  |\n","|   layer3.1                     |   1.117M               |   9.406G   |\n","|    layer3.1.conv1              |    0.262M              |    2.198G  |\n","|    layer3.1.bn1                |    0.512K              |    10.733M |\n","|    layer3.1.conv2              |    0.59M               |    4.946G  |\n","|    layer3.1.bn2                |    0.512K              |    10.733M |\n","|    layer3.1.conv3              |    0.262M              |    2.198G  |\n","|    layer3.1.bn3                |    2.048K              |    42.931M |\n","|   layer3.2                     |   1.117M               |   9.406G   |\n","|    layer3.2.conv1              |    0.262M              |    2.198G  |\n","|    layer3.2.bn1                |    0.512K              |    10.733M |\n","|    layer3.2.conv2              |    0.59M               |    4.946G  |\n","|    layer3.2.bn2                |    0.512K              |    10.733M |\n","|    layer3.2.conv3              |    0.262M              |    2.198G  |\n","|    layer3.2.bn3                |    2.048K              |    42.931M |\n","|   layer3.3                     |   1.117M               |   9.406G   |\n","|    layer3.3.conv1              |    0.262M              |    2.198G  |\n","|    layer3.3.bn1                |    0.512K              |    10.733M |\n","|    layer3.3.conv2              |    0.59M               |    4.946G  |\n","|    layer3.3.bn2                |    0.512K              |    10.733M |\n","|    layer3.3.conv3              |    0.262M              |    2.198G  |\n","|    layer3.3.bn3                |    2.048K              |    42.931M |\n","|   layer3.4                     |   1.117M               |   9.406G   |\n","|    layer3.4.conv1              |    0.262M              |    2.198G  |\n","|    layer3.4.bn1                |    0.512K              |    10.733M |\n","|    layer3.4.conv2              |    0.59M               |    4.946G  |\n","|    layer3.4.bn2                |    0.512K              |    10.733M |\n","|    layer3.4.conv3              |    0.262M              |    2.198G  |\n","|    layer3.4.bn3                |    2.048K              |    42.931M |\n","|   layer3.5                     |   1.117M               |   9.406G   |\n","|    layer3.5.conv1              |    0.262M              |    2.198G  |\n","|    layer3.5.bn1                |    0.512K              |    10.733M |\n","|    layer3.5.conv2              |    0.59M               |    4.946G  |\n","|    layer3.5.bn2                |    0.512K              |    10.733M |\n","|    layer3.5.conv3              |    0.262M              |    2.198G  |\n","|    layer3.5.bn3                |    2.048K              |    42.931M |\n","|   layer3.6                     |   1.117M               |   9.406G   |\n","|    layer3.6.conv1              |    0.262M              |    2.198G  |\n","|    layer3.6.bn1                |    0.512K              |    10.733M |\n","|    layer3.6.conv2              |    0.59M               |    4.946G  |\n","|    layer3.6.bn2                |    0.512K              |    10.733M |\n","|    layer3.6.conv3              |    0.262M              |    2.198G  |\n","|    layer3.6.bn3                |    2.048K              |    42.931M |\n","|   layer3.7                     |   1.117M               |   9.406G   |\n","|    layer3.7.conv1              |    0.262M              |    2.198G  |\n","|    layer3.7.bn1                |    0.512K              |    10.733M |\n","|    layer3.7.conv2              |    0.59M               |    4.946G  |\n","|    layer3.7.bn2                |    0.512K              |    10.733M |\n","|    layer3.7.conv3              |    0.262M              |    2.198G  |\n","|    layer3.7.bn3                |    2.048K              |    42.931M |\n","|   layer3.8                     |   1.117M               |   9.406G   |\n","|    layer3.8.conv1              |    0.262M              |    2.198G  |\n","|    layer3.8.bn1                |    0.512K              |    10.733M |\n","|    layer3.8.conv2              |    0.59M               |    4.946G  |\n","|    layer3.8.bn2                |    0.512K              |    10.733M |\n","|    layer3.8.conv3              |    0.262M              |    2.198G  |\n","|    layer3.8.bn3                |    2.048K              |    42.931M |\n","|   layer3.9                     |   1.117M               |   9.406G   |\n","|    layer3.9.conv1              |    0.262M              |    2.198G  |\n","|    layer3.9.bn1                |    0.512K              |    10.733M |\n","|    layer3.9.conv2              |    0.59M               |    4.946G  |\n","|    layer3.9.bn2                |    0.512K              |    10.733M |\n","|    layer3.9.conv3              |    0.262M              |    2.198G  |\n","|    layer3.9.bn3                |    2.048K              |    42.931M |\n","|   layer3.10                    |   1.117M               |   9.406G   |\n","|    layer3.10.conv1             |    0.262M              |    2.198G  |\n","|    layer3.10.bn1               |    0.512K              |    10.733M |\n","|    layer3.10.conv2             |    0.59M               |    4.946G  |\n","|    layer3.10.bn2               |    0.512K              |    10.733M |\n","|    layer3.10.conv3             |    0.262M              |    2.198G  |\n","|    layer3.10.bn3               |    2.048K              |    42.931M |\n","|   layer3.11                    |   1.117M               |   9.406G   |\n","|    layer3.11.conv1             |    0.262M              |    2.198G  |\n","|    layer3.11.bn1               |    0.512K              |    10.733M |\n","|    layer3.11.conv2             |    0.59M               |    4.946G  |\n","|    layer3.11.bn2               |    0.512K              |    10.733M |\n","|    layer3.11.conv3             |    0.262M              |    2.198G  |\n","|    layer3.11.bn3               |    2.048K              |    42.931M |\n","|   layer3.12                    |   1.117M               |   9.406G   |\n","|    layer3.12.conv1             |    0.262M              |    2.198G  |\n","|    layer3.12.bn1               |    0.512K              |    10.733M |\n","|    layer3.12.conv2             |    0.59M               |    4.946G  |\n","|    layer3.12.bn2               |    0.512K              |    10.733M |\n","|    layer3.12.conv3             |    0.262M              |    2.198G  |\n","|    layer3.12.bn3               |    2.048K              |    42.931M |\n","|   layer3.13                    |   1.117M               |   9.406G   |\n","|    layer3.13.conv1             |    0.262M              |    2.198G  |\n","|    layer3.13.bn1               |    0.512K              |    10.733M |\n","|    layer3.13.conv2             |    0.59M               |    4.946G  |\n","|    layer3.13.bn2               |    0.512K              |    10.733M |\n","|    layer3.13.conv3             |    0.262M              |    2.198G  |\n","|    layer3.13.bn3               |    2.048K              |    42.931M |\n","|   layer3.14                    |   1.117M               |   9.406G   |\n","|    layer3.14.conv1             |    0.262M              |    2.198G  |\n","|    layer3.14.bn1               |    0.512K              |    10.733M |\n","|    layer3.14.conv2             |    0.59M               |    4.946G  |\n","|    layer3.14.bn2               |    0.512K              |    10.733M |\n","|    layer3.14.conv3             |    0.262M              |    2.198G  |\n","|    layer3.14.bn3               |    2.048K              |    42.931M |\n","|   layer3.15                    |   1.117M               |   9.406G   |\n","|    layer3.15.conv1             |    0.262M              |    2.198G  |\n","|    layer3.15.bn1               |    0.512K              |    10.733M |\n","|    layer3.15.conv2             |    0.59M               |    4.946G  |\n","|    layer3.15.bn2               |    0.512K              |    10.733M |\n","|    layer3.15.conv3             |    0.262M              |    2.198G  |\n","|    layer3.15.bn3               |    2.048K              |    42.931M |\n","|   layer3.16                    |   1.117M               |   9.406G   |\n","|    layer3.16.conv1             |    0.262M              |    2.198G  |\n","|    layer3.16.bn1               |    0.512K              |    10.733M |\n","|    layer3.16.conv2             |    0.59M               |    4.946G  |\n","|    layer3.16.bn2               |    0.512K              |    10.733M |\n","|    layer3.16.conv3             |    0.262M              |    2.198G  |\n","|    layer3.16.bn3               |    2.048K              |    42.931M |\n","|   layer3.17                    |   1.117M               |   9.406G   |\n","|    layer3.17.conv1             |    0.262M              |    2.198G  |\n","|    layer3.17.bn1               |    0.512K              |    10.733M |\n","|    layer3.17.conv2             |    0.59M               |    4.946G  |\n","|    layer3.17.bn2               |    0.512K              |    10.733M |\n","|    layer3.17.conv3             |    0.262M              |    2.198G  |\n","|    layer3.17.bn3               |    2.048K              |    42.931M |\n","|   layer3.18                    |   1.117M               |   9.406G   |\n","|    layer3.18.conv1             |    0.262M              |    2.198G  |\n","|    layer3.18.bn1               |    0.512K              |    10.733M |\n","|    layer3.18.conv2             |    0.59M               |    4.946G  |\n","|    layer3.18.bn2               |    0.512K              |    10.733M |\n","|    layer3.18.conv3             |    0.262M              |    2.198G  |\n","|    layer3.18.bn3               |    2.048K              |    42.931M |\n","|   layer3.19                    |   1.117M               |   9.406G   |\n","|    layer3.19.conv1             |    0.262M              |    2.198G  |\n","|    layer3.19.bn1               |    0.512K              |    10.733M |\n","|    layer3.19.conv2             |    0.59M               |    4.946G  |\n","|    layer3.19.bn2               |    0.512K              |    10.733M |\n","|    layer3.19.conv3             |    0.262M              |    2.198G  |\n","|    layer3.19.bn3               |    2.048K              |    42.931M |\n","|   layer3.20                    |   1.117M               |   9.406G   |\n","|    layer3.20.conv1             |    0.262M              |    2.198G  |\n","|    layer3.20.bn1               |    0.512K              |    10.733M |\n","|    layer3.20.conv2             |    0.59M               |    4.946G  |\n","|    layer3.20.bn2               |    0.512K              |    10.733M |\n","|    layer3.20.conv3             |    0.262M              |    2.198G  |\n","|    layer3.20.bn3               |    2.048K              |    42.931M |\n","|   layer3.21                    |   1.117M               |   9.406G   |\n","|    layer3.21.conv1             |    0.262M              |    2.198G  |\n","|    layer3.21.bn1               |    0.512K              |    10.733M |\n","|    layer3.21.conv2             |    0.59M               |    4.946G  |\n","|    layer3.21.bn2               |    0.512K              |    10.733M |\n","|    layer3.21.conv3             |    0.262M              |    2.198G  |\n","|    layer3.21.bn3               |    2.048K              |    42.931M |\n","|   layer3.22                    |   1.117M               |   9.406G   |\n","|    layer3.22.conv1             |    0.262M              |    2.198G  |\n","|    layer3.22.bn1               |    0.512K              |    10.733M |\n","|    layer3.22.conv2             |    0.59M               |    4.946G  |\n","|    layer3.22.bn2               |    0.512K              |    10.733M |\n","|    layer3.22.conv3             |    0.262M              |    2.198G  |\n","|    layer3.22.bn3               |    2.048K              |    42.931M |\n","|  layer4                        |  14.965M               |  0.126T    |\n","|   layer4.0                     |   6.04M                |   50.77G   |\n","|    layer4.0.conv1              |    0.524M              |    4.396G  |\n","|    layer4.0.bn1                |    1.024K              |    21.466M |\n","|    layer4.0.conv2              |    2.359M              |    19.783G |\n","|    layer4.0.bn2                |    1.024K              |    21.466M |\n","|    layer4.0.conv3              |    1.049M              |    8.792G  |\n","|    layer4.0.bn3                |    4.096K              |    85.862M |\n","|    layer4.0.downsample         |    2.101M              |    17.67G  |\n","|   layer4.1                     |   4.463M               |   37.496G  |\n","|    layer4.1.conv1              |    1.049M              |    8.792G  |\n","|    layer4.1.bn1                |    1.024K              |    21.466M |\n","|    layer4.1.conv2              |    2.359M              |    19.783G |\n","|    layer4.1.bn2                |    1.024K              |    21.466M |\n","|    layer4.1.conv3              |    1.049M              |    8.792G  |\n","|    layer4.1.bn3                |    4.096K              |    85.862M |\n","|   layer4.2                     |   4.463M               |   37.496G  |\n","|    layer4.2.conv1              |    1.049M              |    8.792G  |\n","|    layer4.2.bn1                |    1.024K              |    21.466M |\n","|    layer4.2.conv2              |    2.359M              |    19.783G |\n","|    layer4.2.bn2                |    1.024K              |    21.466M |\n","|    layer4.2.conv3              |    1.049M              |    8.792G  |\n","|    layer4.2.bn3                |    4.096K              |    85.862M |\n","|  layer6.conv2d_list            |  1.401M                |  11.746G   |\n","|   layer6.conv2d_list.0         |   0.35M                |   2.936G   |\n","|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.1         |   0.35M                |   2.936G   |\n","|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.2         |   0.35M                |   2.936G   |\n","|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.3         |   0.35M                |   2.936G   |\n","|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n"]}]},{"cell_type":"code","source":["model = deeplab.get_deeplab_v2(\n","    num_classes=NUM_CLASSES,\n","    pretrain=True,\n","    pretrain_model_path=PRETRAIN_MODEL_PATH\n",")\n","\n","iterations = 1000\n","\n","# random RGB image\n","image_np = np.random.rand(1, 3, H, W)\n","image = torch.from_numpy(image_np).float()\n","\n","if torch.cuda.is_available():\n","     model = model.to('cuda')\n","     image = image.to('cuda')\n","\n","latency = []\n","FPS = []\n","\n","# calculate latency and FPS\n","for iter in range(iterations):\n","    start = time.time()\n","    output = model(image)\n","    end = time.time()\n","\n","    latency_i = end - start\n","    latency.append(latency_i)\n","\n","    FPS_i = 1 / latency_i\n","    FPS.append(FPS_i)\n","\n","meanLatency = np.mean(latency) * 1000  # milliseconds\n","stdLatency = np.std(latency) * 1000   # milliseconds\n","meanFPS = np.mean(FPS)\n","stdFPS = np.std(FPS)\n","\n","print(f\"Mean Latency: {meanLatency:.2f} ms\")\n","print(f\"Latency Std Dev: {stdLatency:.2f} ms\")\n","print(f\"Mean FPS: {meanFPS:.2f}\")\n","print(f\"FPS Std Dev: {stdFPS:.2f}\")"],"metadata":{"id":"5oqs3BP8AOo0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750608700509,"user_tz":-120,"elapsed":69105,"user":{"displayName":"Machine Learning Pro Plus","userId":"09241564284541468923"}},"outputId":"4564ec90-9109-479d-cfe5-fd92a70a45b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Deeplab pretraining loading...\n","Mean Latency: 67.94 ms\n","Latency Std Dev: 27.18 ms\n","Mean FPS: 14.95\n","FPS Std Dev: 1.63\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}